# ------------------- template ----------------

@article{xxx,
    selected={false},
    bibtex_show={true},
    abbr={abr}, 
    html={html},
    pdf={pdf},

    title={title},
    author={authors},
    journal={journal},
    year={year},

    abstract={abstract},
}

@inproceedings{yyy,
    selected={false},
    bibtex_show={true},
    abbr={abr}, 
    html={html},
    pdf={pdf},

    title={title},
    author={author},
    booktitle={Proceeding of 20th International Congress of Phonetic Sciences},
    year={year},

    abstract={abstract},
}
# ------------------- 2023 ----------------

@article{coretta2023multidimensional,
    selected={true},
    bibtex_show={true},
    abbr={AMPPS}, 
    html={https://doi.org/10.1177/25152459231162567},
    pdf={https://journals.sagepub.com/doi/reader/10.1177/25152459231162567/},

    title={Multidimensional signals and analytic flexibility: Estimating degrees of freedom in human speech analyses},
    author={Coretta, Ste and Casillas, Joseph V and ... and Zhang, Cong and ... and Roettger, Timo B},
    journal={Advances in Methods and Practices in Psychological Sciences},
    year={2023},

    abstract={Recent empirical studies have highlighted the large degree of analytic flexibility in data analysis which can lead to substantially different conclusions based on the same data set. Thus, researchers have expressed their concerns that these researcher degrees of freedom might facilitate bias and can lead to claims that do not stand the test of time. Even greater flexibility is to be expected in fields in which the primary data lend themselves to a variety of possible operationalizations. The multidimensional, temporally extended nature of speech constitutes an ideal testing ground for assessing the variability in analytic approaches, which derives not only from aspects of statistical modeling, but also from decisions regarding the quantification of the measured behavior. In the present study, we gave the same speech production data set to 46 teams of researchers and asked them to answer the same research question, resulting in substantial variability in reported effect sizes and their interpretation. Using Bayesian meta-analytic tools, we further find little to no evidence that the observed variability can be explained by analysts' prior beliefs, expertise or the perceived quality of their analyses. In light of this idiosyncratic variability, we recommend that researchers more transparently share details of their analysis, strengthen the link between theoretical construct and quantitative system and calibrate their (un)certainty in their conclusions.},
}


@inproceedings{zhang2023language-redundancy,
    selected={false},
    bibtex_show={true},
    abbr={ICPhS}, 
    html={html},
    pdf={pdf},

    title={Language redundancy effects on F0: A preliminary controlled study},
    author={Zhang, Cong and Lai, Catherine and Napoleão de Souza, Ricardo and Turk, Alice and Bögel, Tina},
    booktitle={Proceeding of 20th International Congress of Phonetic Sciences},
    year={2023},

    abstract={Previous research suggests that words with a high level of language redundancy (i.e. recognition likelihood from familiarity and predictability based
    on syntactic, pragmatic, and semantic factors) have reduced acoustic salience, such as shorter duration and reduced vowels. The Smooth Signal Redundancy Hypothesis proposes that acoustic salience is controlled via prosodic structure, and makes the prediction that parameters such as fundamental frequency should also be affected by language redundancy. This study investigates the relationship of F0 with lexical frequency, together with bigram (verb-adjective or adjective-noun) frequency and the ratio between these two bigram frequencies. Results from a carefully controlled experiment with quadruplets of minimal pairs suggests that language redundancy can affect fundamental frequency in English.},
}


@article{kim2023collecting,
    selected={true},
    bibtex_show={true},
    abbr={gamification}, 
    html={https://doi.org/10.1093/applin/amad039},
    pdf={https://academic.oup.com/applij/advance-article/doi/10.1093/applin/amad039/7223350?utm_source=authortollfreelink&utm_campaign=applij&utm_medium=email&guestAccessKey=6ebc0401-70dd-4539-982e-25e6608e3a34&login=true},

    author = {Kim, Yoolim and Kogan, Vita V and Zhang, Cong},
    title = "{Collecting Big Data Through Citizen Science: Gamification and Game-based Approaches to Data Collection in Applied Linguistics}",
    journal = {Applied Linguistics},
    pages = {amad039},
    year = {2023},
    abstract = "{Gamification of behavioral experiments has been applied successfully to research in a number of disciplines, including linguistics. We believe that these methods have been underutilized in applied linguistics, in particular second-language acquisition research. The incorporation of games and gaming elements (gamification) in behavioral experiments has been shown to mitigate many of the practical constraints characteristic of lab settings, such as limited recruitment or only achieving small-scale data. However, such constraints are no longer an issue with gamified and game-based experiments, and as a result, data collection can occur remotely with greater ease and on a much wider scale, yielding data that are ecologically valid and robust. These methods enable the collection of data that are comparable in quality to the data collected in more traditional settings while engaging far more diverse participants with different language backgrounds that are more representative of the greater population. We highlight three successful applications of using games and gamification with applied linguistic experiments to illustrate the effectiveness of such approaches in a greater effort to invite other applied linguists to do the same.}",
    issn = {0142-6001},
    doi = {10.1093/applin/amad039},
}


# ------------------- 2022 ----------------

@article{zhu2022bootstrapping,
    selected={true},
    bibtex_show={true},
    abbr={EMNLP Findings}, 
    pdf={https://aclanthology.org/2022.findings-emnlp.81.pdf},
    html={https://aclanthology.org/2022.findings-emnlp.81/},
    code={https://github.com/lingjzhu/spoken_sent_embedding},

    title = {Bootstrapping meaning through listening: Unsupervised learning of spoken sentence embeddings},
    author = {Zhu, Jian  and Tian, Zuoyu and Liu, Yadong and Zhang, Cong and Lo, Chia-wen},
    year = {2022},

    journal = {Findings of Empirical Methods in Natural Language Processing},

    abstract={Inducing semantic representations directly from speech signals is a highly challenging task but has many useful applications in speech mining and spoken language understanding. This study tackles the unsupervised learning of semantic representations for spoken utterances. Through converting speech signals into hidden units generated from acoustic unit discovery, we propose WavEmbed, a multimodal sequential autoencoder that predicts hidden units from a dense representation of speech. Secondly, we also propose S-HuBERT to induce meaning through knowledge distillation, in which a sentence embedding model is first trained on hidden units and passes its knowledge to a speech encoder through contrastive learning. The best performing model achieves a moderate correlation (0.5~0.6) with human judgments, without relying on any labels or transcriptions. Furthermore, these models can also be easily extended to leverage textual transcriptions of speech to learn much better speech embeddings that are strongly correlated with human annotations. Our proposed methods are applicable to the development of purely data-driven systems for speech mining, indexing and search.}
   }


 @article{sun2022task,  
    selected={true},
    bibtex_show={true},
    abbr={EMNLP Findings}, 
    pdf={https://www.scielo.br/j/delta/a/QwGKgDkWkvJbNsZ9CrgZNvb/?format=pdf&lang=en},
    html={https://doi.org/10.1590/1678-460X202258943},
    code={https://github.com/lingjzhu/spoken_sent_embedding},

    author={Sun, Yuqi and Zhang, Cong},  
    year={2022},  
    title={Task effect on L2 rhythm production by Cantonese learners of Portuguese},  
    volume={38},  
    ISSN={0102-4450},  
    DOI={10.1590/1678-460X202258943},  
    number={3},  
    journal={DELTA: Documentação de Estudos em Lingüística Teórica e Aplicada},  
    publisher={Pontifícia Universidade Católica de São Paulo - PUC-SP},  
    pages={202258943},
    abstract = {This study examines L2 Portuguese speech produced by eight native Cantonese speakers from Macao, China. The aims of this study are to investigate (1) whether the speech rhythm in L2 Portuguese is more source-like (more similar to Cantonese) or more target-like (more similar to Portuguese), and (2) whether L2 speech rhythm differs across three different tasks: a reading task, a retelling task, and an interpreting task. Seven rhythm metrics, i.e., %V, ΔC, ΔV, VarcoC, VarcoV, rPVI_C, and nPVI_V, were adopted for comparison and investigation. The results showed that L2 Portuguese rhythm produced by Cantonese speakers differed from L1 Portuguese speakers’ rhythm. R-deletion and vowel epenthesis were the reasons for the variabilities and instabilities of L2 Portuguese production by Cantonese learners, as they affect the duration and the number of vowel intervals and consonantal intervals. Moreover, in Cantonese learners’ L2 Portuguese production, the semi-spontaneous tasks (retelling and interpreting) presented a significant difference from the reading task. The driving force for such a difference was the cognitive load behind the tasks.}}


@inproceedings{zhu2022byt5-g2p,
    selected=True,
    bibtex_show={true},
    abbr={Interspeech},
    pdf={https://arxiv.org/pdf/2204.03067.pdf},
    code={https://github.com/lingjzhu/CharsiuG2P},

    title={ByT5 model for massively multilingual grapheme-to-phoneme conversion},
    author={Zhu, Jian and Zhang, Cong and Jurgens, David},
    year={2022},

    booktitle={Interspeech 2022},
    
    abstract={In this study, we tackle massively multilingual grapheme-to-phoneme conversion through implementing G2P models based on ByT5. We have curated a G2P dataset from various sources that covers around 100 languages and trained large-scale multilingual G2P models based on ByT5. We found that ByT5 operating on byte-level inputs significantly outperformed the token-based mT5 model in terms of multilingual G2P. Pairwise comparison with monolingual models in these languages suggests that multilingual ByT5 models generally lower the phone error rate by jointly learning from a variety of languages. The pretrained model can further benefit low resource G2P through zero-shot prediction on unseen languages or provides pretrained weights for finetuning, which helps the model converge to a lower phone error rate than randomly initialized weights. To facilitate future research on multilingual G2P, we make available our code and pretrained multilingual G2P models at: https://github.com/lingjzhu/CharsiuG2P.}
  }


@inproceedings{zhu2022phone-charsiu,
    selected={false},
    bibtex_show={true},
    abbr={ICASSP},
    pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9746112},
    html={https://doi.org/10.1109/ICASSP43922.2022.9746112},
    code={https://github.com/lingjzhu/charsiu},

      title={Phone-to-audio alignment without text: A Semi-supervised Approach},
      author={Zhu, Jian and Zhang, Cong and Jurgens, David},
      booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
      year={2022},
    
      abstract={The task of phone-to-audio alignment has many applications in speech research. Here we introduce two Wav2Vec2-based models for both text-dependent and text-independent phone-to-audio alignment. The proposed Wav2Vec2-FS, a semi-supervised model, directly learns phone-to-audio alignment through contrastive learning and a forward sum loss, and can be coupled with a pretrained phone recognizer to achieve text-independent alignment. The other model, Wav2Vec2-FC, is a frame classification model trained on forced aligned labels that can both perform forced alignment and text-independent segmentation. Evaluation results suggest that both proposed methods, even when transcriptions are not available, generate highly close results to existing forced alignment tools. Our work presents a neural pipeline of fully automated phone-to-audio alignment.}
}


@inproceedings{gryllia2022many-shape,
    selected={false},
    bibtex_show={true},
    abbr={Speech Prosody}, 
    html = {https://doi.org/10.21437/SpeechProsody.2022-153},
    pdf = {https://www.isca-speech.org/archive/pdfs/speechprosody_2022/gryllia22_speechprosody.pdf},
    code = {https://osf.io/emcfg/},

    author = {Gryllia, Stella and Arvaniti, Amalia and Zhang, Cong and Marcoux, Katherine},
    booktitle = {Speech Prosody 2022},
    title = {{The many shapes of H*}},
    year = {2022},

    abstract = {We examined individual and task-related variability in the realization of Greek nuclear H* followed by L-L% edge tones. The accents (N = 748) were elicited from native speakers of Greek, producing scripted and unscripted speech, and examined using functional Principal Components Analysis. The accented vowel onset was used for landmark registration to capture accent shape and the alignment of the fall. The resulting PCs were analysed using LMEMs (fixed factors: speaker; task type (scripted, unscripted); accented syllable distance from the analysis window offset, to examine the effects of tonal crowding). Tonal scaling and the steepness of the fall (reflected in PC1 and PC2 respectively) changed by task in ways that differed across speakers. PC3, which captured accent shape, also varied by speaker, reflecting shape differences between a rise-fall and (the expected) plateau-plus-fall realization. Tonal crowding did not have consistent effects. In short, the overall accent shape and the alignment of the accentual fall varied by speaker and task. These results hint at substantial variability in tonal realization. At the same time, they indicate that tonal alignment is not as consistent as is sometimes portrayed and thus it should not be the sole criterion for tone categorization.}
    }


@inproceedings{arvaniti2022distangling,
    selected={false},
    bibtex_show={true},
    abbr={Speech Prosody}, 
    html = {https://doi.org/10.21437/SpeechProsody.2022-170},
    pdf = {https://www.isca-speech.org/archive/pdfs/speechprosody_2022/arvaniti22_speechprosody.pdf},
    code = {https://osf.io/wm7bc/},

    author = {Arvaniti, Amalia and Gryllia, Stella and Zhang, Cong and Marcoux, Katherine},
    booktitle = {Speech Prosody 2022},
    title = {{Disentangling emphasis from pragmatic contrastivity in the English H* $\sim$ L+H* contrast}},
    year = {2022},

    abstract = {English H* and L+H* indicate new and contrastive information respectively, though some argue the difference between them is solely one of phonetic emphasis. We used (modified) Rapid Prosody Transcription to test these views. Forty-seven speakers of Standard Southern British English (SSBE) listened to 86 SSBE utterances and marked the words they considered prominent or emphatic. Accents (N = 281) were independently coded as H* or L+H* using phonetic criteria, and as contrastive or non-contrastive using pragmatic criteria. If L+H* is an emphatic H*, all L+H*s should be more prominent than H*s. If the accents mark pragmatic information, contrastivity should drive responses. Contrastive accents and L+H*s were considered more prominent than non-contrastive accents and H*s respectively. Individual responses showed different strategies: for some participants, all L+H*s were more prominent than H*s, for others, contrastive accents were more prominent than non-contrastive accents, and for still others, there was no difference between categories. These results indicate that a reason for the continuing debate about English H* and L+H* may be that the two accents form a weak contrast which some speakers acquire and attend to while others do not.}
}


# ------------------- 2021 ----------------


@inproceedings{zhang2021synchronising,
    selected={true},
    bibtex_show={true},
    abbr={Interspeech},
    html = {https://www.isca-speech.org/archive/interspeech_2021/zhang21i_interspeech.html},
    pdf = {https://www.isca-speech.org/archive/pdfs/interspeech_2021/zhang21i_interspeech.pdf},
    code = {https://osf.io/8m5bj/?view_only=c87fe156d1874ffba8a16cc363b225af},
    
    author={Cong Zhang and Jian Zhu},
    title={{Synchronising Speech Segments with Musical Beats in Mandarin and English Singing}},
    year=2021,
    booktitle={Interspeech 2021},
    
    pages={1199--1203},
    doi={10.21437/Interspeech.2021-1841},
    
    abstract={Generating synthesised singing voice with models trained on speech data has many advantages due to the models’ flexibility and controllability. However, since the information about the temporal relationship between segments and beats are lacking in speech training data, the synthesised singing may sound off-beat at times. Therefore, the availability of the information on the temporal relationship between speech segments and music beats is crucial. The current study investigated the segment-beat synchronisation in singing data, with hypotheses formed based on the linguistics theories of P-centre and sonority hierarchy. A Mandarin corpus and an English corpus of professional singing data were manually annotated and analysed. The results showed that the presence of musical beats was more dependent on segment duration than sonority. However, the sonority hierarchy and the P-centre theory were highly related to the location of beats. Mandarin and English demonstrated cross-linguistic variations despite exhibiting common patterns.}
}

@article{zhang2021comparing,
    selected={true},
    bibtex_show={true},
    abbr={JASA},
    html = {https://pubs.aip.org/asa/jasa/article/149/6/3910/1059288/Comparing-acoustic-analyses-of-speech-data},
    pdf = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8269758/pdf/JASMAN-000149-003910_1.pdf},

    author = {Zhang, Cong and Jepson, Kathleen and Lohfink, Georg and Arvaniti, Amalia},
    year = {2021},
    title = {{Comparing acoustic analyses of speech data collected remotely}},
    
    doi = {10.1121/10.0005132},
    issn = {0001-4966},
    journal = {The Journal of the Acoustical Society of America},
    number = {6},
    pages = {3910--3916},
    publisher = {Acoustical Society of America},
    volume = {149},

    abstract = {Face-to-face speech data collection has been next to impossible globally due to COVID-19 restrictions. To address this problem, simultaneous recordings of three repetitions of the cardinal vowels were made using a Zoom H6 Handy Recorder with external microphone (henceforth H6) and compared with two alternatives accessible to potential participants at home: the Zoom meeting application (henceforth Zoom) and two lossless mobile phone applications (Awesome Voice Recorder, and Recorder; henceforth Phone). F0 was tracked accurately by all devices; however, for formant analysis (F1, F2, F3) Phone performed better than Zoom, i.e. more similarly to H6, though data extraction method (VoiceSauce, Praat) also resulted in differences. In addition, Zoom recordings exhibited unexpected drops in intensity. The results suggest that lossless format phone recordings present a viable option for at least some phonetic studies.},
    
}


# ------------------- 2020 ----------------

@inproceedings{zhang2020segment-sing,
    selected={true},
    bibtex_show={true},
    abbr={speech prosody}, 
    html={https://www.isca-speech.org/archive/speechprosody_2020/zhang20c_speechprosody.html},
    pdf={pdf},
    code={https://osf.io/ead87/?view_only=c87fe156d1874ffba8a16cc363b225af},
    presentation={https://osf.io/ybdup?view_only=c87fe156d1874ffba8a16cc363b225af},

    author={Cong Zhang and Xinrong Wang},
    title={{Segment Duration and Proportion in Mandarin Singing}},
    year=2020,
    booktitle={Proc. Speech Prosody 2020},
    pages={596--600},
    doi={10.21437/SpeechProsody.2020-122}
}


# ------------------- 2019 ----------------

@inproceedings{Zhang2019a,
 selected={true},
    bibtex_show={true},
    abbr={ICPhS}, 
    pdf={https://icphs2019.org/icphs2019-fullpapers/pdf/full-paper_930.pdf},

    author = {Zhang, Cong},
    booktitle = {Proceeding of 19th International Congress of Phonetic Sciences},
    year = {2019},
    title = {{Stacking and Unstacking Prosodies : The Production and Perception of Sentence Prosody in a Tonal Language}},
    keywords = {intonation,tianjin mandarin,tone},
    abstract = {Teasing apart lexical prosody and sentence prosody has been one of the most difficult tasks in the study of intonational tunes in tonal languages. Are different prosodic manifestations stacked, or are they an integrated whole? With evidence from production and perception data of the intonational yes/no question tune in Tianjin Mandarin at sentence level, this paper proposes that (1) lexical tonal alterations (a.k.a tone sandhi) are lexical-level prosody and do not belong to sentence-level tune; (2) pitch accents induced by information structure are “intra-tune” features, which are such sentence-level prosody features that do not cause sentence type change. Despite being sentence-level prosody features, they are not a part of the tune for intonational yes/no question.}
}


# ------------------- 2018 ----------------

@phdthesis{Zhang2018dphil,
    selected={false},
    bibtex_show={true},
    abbr={Thesis}, 
    html={https://ora.ox.ac.uk/objects/uuid:3149a35c-e6c2-4f43-a41a-bdc08ebf08f6},
    pdf={https://ora.ox.ac.uk/objects/uuid:3149a35c-e6c2-4f43-a41a-bdc08ebf08f6/files/m7641933f05b45acbbc25093eb87fe54d},

    author = {Zhang, Cong},
    keywords = {Doctoral thesis},
    school = {University of Oxford},
    title = {{Tianjin Mandarin Tones and Tunes}},
    year = {2018},

    abstract={
    Lexical tones and intonational tunes are both mainly realised through pitch modulation. What role does intonation play in a language which has a lexical tonal contrast? Can one separate ‘tone’ from ‘intonation’? If yes, how do lexical tones interact with intonational tunes? In order to answer these questions, this thesis investigates how tone and intonation interact during production and perception in Tianjin Mandarin, by means of examining the components of different intonational tunes under the Autosegmental-Metrical (AM) Framework (Pierrehumbert, 1980), and the cues native listeners use during the tune identification process.
    
    Chapter 1 – 3 are the introductory chapters: Chapter 1 introduces the topic of research, and sketches the three research goals for this thesis – the theoretical goal, the documentation goal, and the methodological goal; Chapter 2 addresses the theoretical foundation of this thesis – the AM theory; and Chapter 3 outlines the linguistic background of Tianjin Mandarin.
    
    Chapter 4 presents production studies of the tune of intonational Yes/No questions (IntQ) in Tianjin Mandarin. A total of six native Tianjin speakers were recorded for monosyllabic words in isolation (Mono(ISO)) and monosyllabic words as sentence prominence (Mono(SEN)), with statement tune and IntQ tune, respectively. The results show that when a monosyllabic word is produced in isolation, the IntQ tune has a raised register, and a floating H% boundary tone at the end of the intonational phrase. When a monosyllabic word is in sentence prominence position, the IntQ tune also has a raised register, a floating H% boundary tone, as well as a H* pitch accent coming from the focus and a post-focus compression. The IntQ tune is:
    
    [H* pitch accent + (post-focus compression) + floating H̥% boundary tone] higher register.
    
    To further investigate how the IntQ tune is represented, three perception experiments were conducted on monosyllabic words in isolation, monosyllabic words as sentence prominence, and sentences with monosyllabic words as prominence in Chapter 5. A total of 28 native Tianjin Mandarin speakers participated in the experiments. They were asked to identify the tunes (yes-no question or statement) of the audio stimuli. The accuracy of their responses and reaction time together show that they strongly prefer the H-Rising lexical tone for IntQs, and L-Falling lexical tone for statements, which indicate that they look for the low register information during the identification of statements, and a H boundary tone for the IntQ tune.
    
    Another important tune, chanted call (CC) tune, was also studied to further investigate the possibilities of intonational tunes in a tonal language in Chapter 6. Six native speakers’ production of monosyllabic words and disyllabic words were recorded. The results show that there is a L% boundary tone at the end of the intonational phrase, regardless of the lexical tones. Different from the IntQ data, the L% boundary tone is phonetically manifested and overrode the lexical tone contours. A H* pitch accent was found to be associated with the H of each lexical tone. Lengthening was also found in the CC tune. The CC tune in Tianjin Mandarin can be represented as follows:
    
    [[H*]sustained]higher register + L%.}
    }

@inproceedings{Zhang2018,
    selected={true},
    bibtex_show={true},
    abbr={Speech Prosody}, 
    html={https://www.isca-speech.org/archive/speechprosody_2018/zhang18c_speechprosody.html},
    pdf={https://www.isca-speech.org/archive/pdfs/speechprosody_2018/zhang18c_speechprosody.pdf},

    author = {Zhang, Cong},
    title = {{Chanted Call Tune in Tianjin Mandarin: Disyllabic Calls}},
    year = {2018},
    booktitle = {9th International Conference on Speech Prosody 2018},
    doi = {10.21437/SpeechProsody.2018-106},
    pages = {522--526},
    publisher = {ISCA},
    abstract ={This paper examines the chanted call tune in Tianjin Mandarin in order to investigate the possibilities of intonational components, i.e. pitch accents, boundary tones, etc., in a tonal language. Six native Tianjin speakers’ production of disyllabic names and kinship terms were recorded. The speech materials were composed of a set of left-prominent disyllabic names and a set of right-prominent disyllabic names. The results show that there is a L% boundary tone at the end of the intonational phrase, regardless of the lexical tones. Different from the IntQ data, the L% boundary tone is phonetically manifested and overrode the lexical tone contours. A H* pitch accent was found to be associated with the H of each lexical tone. Lengthening was also found in the CC tune. The CC tune in Tianjin Mandarin can be represented as follows: [[H*]sustained]higher register + L%.}

}

# ------------------- before 2018 ----------------

@inproceedings{wright2015disfluency,
    selected={false},
    bibtex_show={true},
    abbr={fluency}, 
    pdf={https://shorturl.at/cpsST},

    author = {Wright, Clare and Zhang, Cong},
    title = {{The Effect of Study Abroad Experience on L2 Mandarin Disfluency in Different Types of Tasks}},
    year = {2015},
    booktitle = {Proceeding of The Disfluency in Spontaneous Speech},
    editor = {Lickley, Robin},
    keywords = {fluency,l2 mandarin,study abroad},
    abstract = {Disfluency is a common phenomenon in L2 speech, especially in beginners’ speech. Whether studying abroad can help with reducing their disfluency or not remains debated. We examined longitudinal data from 10 adult English instructed learners of Mandarin measured before and after ten months of studying abroad (SA) in this paper. We used two speaking tasks comparing pre-planned vs. unplanned spontaneous speech to compare differences over time and between tasks, using eight linguistic and temporal fluency measures (analysed using CLAN and PRAAT). Overall mean linguistic and temporal fluency scores improved significantly (p < .05), especially speech rate (p <.01), supporting the general claim that SA favours oral development, particularly fluency. Further analysis revealed task differences at both times of measurement, but with greater improvement in the spontaneous task.}

}


@article{wright2014fluency,
    selected={false},
    bibtex_show={true},
    abbr={fluency}, 
    pdf={https://centaur.reading.ac.uk/37687/1/NWPL%20pre-publication.pdf},

    author = {Wright, Clare and Zhang, Cong},
    title = {{Examining the Effects of Study Abroad on Mandarin Chinese Language Development among UK University Learners}},
    year = {2014},

    journal = {Newcastle Working Papers in Linguistics},
    keywords = {fluency},
    pages = {67--84},
    volume = {20},
    abstract = {This study tracked ten third-year English students learning Mandarin Chinese as a second language (L2) at a UK university, to examine changes in L2 Mandarin during an eight-month period spent studying abroad (SA). We used three writing tasks and four speaking tasks as measures of writing and speaking proficiency, to assess total output, grammatical accuracy, lexical development, pronunciation and fluency, repeated before and after SA in China. Overall mean oral proficiency scores improved significantly (p < .05), especially speech rate (p <.01), supporting the claim that SA favours fluency development (Freed et al. 2004), although the measures highlighted difficulties in clarifying precisely how to assess oral proficiency. Written proficiency showed fewer marked improvements: only one writing test (an untimed short essay) significantly improved in length (p <.05), and increased complex grammar (use of de-relative clause morphemes, p <.001). A sub-group (n=7) provided quantitative data on L2 Mandarin use at different times during SA, showing clear individual differences, highlighting the value of capturing details of students’ experiences during SA (Regan et al. 2009). We also note the lack of standardised linguistically-informed measures for tracking development in L2 Mandarin (Freed et al. 2004; Pallotti 2009; De Jong et al. 2012). Further research is therefore much needed to identify  systematic linguistic development in L2 Mandarin, and also to bridge theory and practice in L2 Mandarin language teaching to clarify the interconnecting factors that affect L2 Mandarin language development.}
}


@article{Zhang2014a,
   selected={false},
    bibtex_show={true},
    abbr={feedback}, 
    html={http://st-annes-mcr.org.uk/staar/publications/staar-5-2014/zhang-2014-the-perception-of-mandarin-lexical-tones-by-non-native-speakers/},
    pdf={https://centaur.reading.ac.uk/37687/1/NWPL%20pre-publication.pdf},

    author = {Zhang, Cong},
    journal = {St. Anne's Annual Review},
    pages = {105--125},
    title = {{The effect of immediate feedback on the perception of Mandarin lexical tones by non-native speakers of Mandarin}},
    volume = {5},
    year = {2014},
    abstract = { Lexical tone is one of the most difficult issues in learning Mandarin as a foreign language. Various efforts have been made by training non-native speakers to improve the perception of Mandarin lexical tones. Immediate feedback, as an essential and efficient way of perceptual learning, however, has been understudied. An AX discrimination task is used to test whether the participants’ perception of Mandarin lexical tones improves after being given immediate feedback. The result shows an evident effect of immediate feedback on the perception of Mandarin lexical tones, both within the experiment groups as well as between the experiment group and the control group}
}



